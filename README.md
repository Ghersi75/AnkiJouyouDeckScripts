# Anki Jouyou Deck Scripts
The goal of this project is to create an anki deck with all jouyou kanji, meanings, sentences, ideally pictures, voice recording of sentences, and most common readings. Additional data may be provided as well.

## What this project will make
- Jouyou deck split by grade, and cards sorted by frequency based on top 2500 most frequent kanji. If not in that set, the kanji will go towards the end
- Frequency deck based on frequency from frequency 2500 json/txt file pulled from jisho admin's github. This file is 8 years old so it might be slightly off, but I assume it will hold up for the most part
- Wanikani levels maybe? This would be useful for those of us who want to follow this level based system but don't wanna have deal with wanikani locking you in at each level without option to move on on your own

## Tools Used
- Scripting: Python is being used for all scripting needs since it's simple to work with.
- Kanji Data:
  - [KanjiApi](https://kanjiapi.dev/): Used to retrieve any necessary data for kanji such as jlpt level, readings, and a couple other fields
  - [Kanji Datasets](https://github.com/davidluzgouveia/kanji-data): A couple json files already containing some good starting data in terms of kanji. I was mistaken in my initial understanding of this data set. I initially assumed JLPT and Jouyou kanji aligned perfectly, but they do not. This set contains the kanji as needed, and there's actually nothing missing from it. Some kanji are in here and may not be in the N1 and vice versa. If everything goes well, I will likely create a separate deck for JLPT Kanji as well for the missing Kanji, or all of it as a deck. Have yet to see what happens.
  - [Amazon Polly](https://aws.amazon.com/polly/): This will likely be used for the Text-To-Speech functionality for sentences and readings. May change in the future
  - [Tatoeba API](https://en.wiki.tatoeba.org/articles/show/api#api): This will likely end up being used for example sentences. A discord user from a large english-japanese exchange server did mention that tatoeba may not be the most accurate, so I will try my best to be careful. Unfortunately I don't have the comprehension level nor the time to look through what will likely be thousands of sentences, so I'll try to add some sort of feedback system at some point later down the line. Or I'll just release it and let people change sentences as they see fit within their own Anki application.

___
## What happened in the end
This project was fun to work on even though it was only a couple days worth of work. Unfortunately it doesn't make sense to keep going since I've found better decks out there and the way things are going now, the decks generated by this project would likely not be good for learning anyway, and here's why.
- The Tatoeba API, while being interesting to mess around with and seemingly very useful for searching sentences with kanji by reading, is known for not being very accurate. A lot of sentences either are incorrect or unnatural sounding. This is because a portion of the sentences have been written by non-natives as part of their own learning. It's unfortunate that this was the only public API that I could find with this search feature.
- Text-To-Speech (TTS) may be inaccurate and I wouldn't be able to tell. I am no expert in Japanese, but I do know that [pitch accent](https://en.wikipedia.org/wiki/Japanese_pitch_accent) is an important part of what makes natives different from non natives, among other things of course. Since I am not great with pitch accent, I wouldn't be able to tell correct pitch apart from incorrect pitch accent, and AWS Polly (TTS of choice) isn't great with pitch accents from what I've heard. In general, most TTS software isn't great at this.
- Creating 2000+ Anki cards would likely be easy to do with the help of code in a couple weeks at most, but checking all those cards 1 by 1 would take much longer. Additionally, since I'm nowhere near native, I would need the help of a native Japanese speaker to verify that each card is indeed correct. 

## How this could be done better
The point of this project was to create custom anki decks once a database of words, sentences, audio recordings of said sentences, and other relevant data, was collected. Using API's that may not have accurate data is not the best way to do this. 

To collect accurate data, the help of native speakers would be needed to not only create sentences and translate them accurately, but also read them aloud in a clear and pitch accurate manner (There's dialects and variations in pitch nowadays depending on the generation as well). 

### The main problem is getting **accurate** data